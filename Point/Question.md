

## Golang

* channel
* goroutine
* 

## PHP

## Linux

## Docker

## MySQL

## Redis

## Elasticsearch

## Kong

## 算法

* 冒泡
* 快排
* LRU

## TCP/IP、HTTP(网络协议)

## DevOps

## MongoDB

## ETCD

## AES(ddb、rib、elb)

## elop




* goroutine

  go通过语言层面实现了协成，比系统层面的线程更轻量，其实就使goroutine，是程序执行流的最小单位，当启动main函数时就创建了一个主goroutine，同时也可以通过go方法创建更多goroutine，goroutine同样也支持并发，可以运行在多个线程之上，线程连接go的处理器，通过处理器调度goroutine，控制它的运行和等待，这是MPG模型，不同的goroutine之间通过channel来实现通讯。

  使用goroutine的优势是：

  ​	从用户态层面就能控制调度；

  ​	goroutine是属于用户空间的，避免了内核空间和用户空间的切换成本；

  ​	goroutine占用内存非常小，可创建非常多的实例；

* channel

  channel是提供goroutine之间通信的管道，channel分为有缓存和无缓存，当设置了有缓存channel时，缓存中数据满了的情况下，发送方将进入阻塞，直到接收方读取了缓存中数据，发送方才会被唤醒，当缓存为空时，接收方将进入阻塞，直到发送方向channel中传入数据，才会唤醒接收方goroutine。channel内部原理是通过互斥锁来控制缓存中数据的copy，channel在go中是一个结构体，当我们实例化这个结构体时，返回的是这个实例化的指针，channel只关心数据接受和发送，并不关系两边的goroutine，这样两边就实现了结偶

  实际场景中通过channel来实现不同goroutine之间的通信，或者通过channel来控制并发数量；

* 进程：系统分配给独立运行的程序一块资源运行单元；每个进程都有自己的独立内存空间，他们是相互独立的；

* 线程：进程内部程序运行的活动单元，一个进程中可能会有多个线程，线程他们相互独立，共享进程的全部资源，线程上下文切换很快，开销相对较小，但是如果线程挂了，进程也会死掉；

* 协成：是用户态的轻量级线程，协成的调度是有用户空间控制的

* golang锁有哪些

  通过channel实现

  定一个channel，一端接受，处于阻塞状态，通过goroutine实现业务逻辑，在方法执行完向channel中传值

  Mutex锁实现	Lock Unlock

  Redis分布式锁

  waitGroup 控制并发 Add 、 wait、done

* channel有无缓冲区别、原理、使用场景

  channel有缓冲区，推送方在缓冲区满了就会阻塞，接收方在缓存区为空的情况下就会阻塞

  channel无缓冲区，指接收方和推送方没有都准备好时，会阻塞；

  原理：

  channel是由一个buf、sendx、recvx、lock、sendq、recvq等实现的一个结构体；

  buf：存放缓冲的循环列表

  sendx：记录buf中发送方当前发送位置的index

  resvx：记录buf中接收方当前接受的index

  lock：锁，互斥锁

  sendq：发送的协成队列，当有多个发送方阻塞时，会存入该队列中

  recvq：接受的协成队列，当有多个接收方阻塞时，会存入该队列中

  实例化一个channel的结构体返回的是一个指针类型，

  ````
  ch := make(chan int, 3)
  ````

  实例化一个buf长度为3的channel

  ````
  ch <- 1
  ````

  当向channel中send数据时，会先锁住channel，然后才向channel的buf中copy数据，当buf中数据满了则停止copy

  ````
  <- ch
  ````

  当向channel中接受数据时，同样会先锁住channel，然后从channel的buf中coopy出数据

  buf是个循环链表，会根据sendx、和recvx标示的位置顺序的copy数据，这符合FIFO的原则(first into first out)

  当buf满了后，继续send，当bu为空时，recv就是阻塞。因为goroutine是用户态的协成，通过go调度器使goroutine阻塞，唤醒其他goroutine，同时阻塞的goroutine会抽象成包含它的指针和send元素的sudog结构体保存在sendq或者recvq队列中；

* golang 调度器、调度原理，并发原理

  并发：在一段时间内两个任务都执行完成，只关心这段时间内两个任务都完成，不关心任何一个时间点是否两个任务都在执行；

  并行：在一段时间内的任意一个时间点，两个任务都在执行；

  并发包含并行

   __不要以共享内存的形式来通信，要以通信的形式来共享内存__ 

  go语言就是通过channel管道来通信实现共享内存；

  无论语言形态何种并发模型，到了操作系统层面都是以线程的形式存在，操作系统根据资源的访问权限不同，体系架构分为 __用户空间__ 和 __内核空间__ 

   __内核空间：__ 主要操作访问系统层面的资源CPU、IO、内存为上层程序提供最基本的基础资源；

   __用户空间：__ 程序活动的空间，用户空间不可以直接访问系统层面资源，必须调用“系统调用”、“库函数”，“Shell脚本”来调用内核空间获取资源；

* golang协成比线程轻量

  goroutine从用户态就能控制调度；

  goroutine属于用用户空间，避免了内核空间和用户空间的切换成本；

  goroutine占用资源非常小，可以创建很多；

* PHP pcntl异步原理

  通过fock创建子进程，子进程会复制主进程上下文，fock通过返回值不同可以判断当前处于主进程还是子进程；

* IO多路复用

* 用户态：用户程序的活动空间，无法直接操作系统资源。

* 内核态：提供用户态可以访问系统资源的空间

* 用户态->内核态

  1. 用户态将数据存放在寄存器中，或者使用参数创建一个堆栈，里面存放需要操作系统提供的服务
  2. 用户态程序执行陷阱指令
  3. CPU切换到内核态，并跳到内存指定位置的指令，这些指令是操作系统的一部分，属于操作系统，不可被用户态访问；
  4. 陷阱指令会执行用户态是存入内存的数据参数，执行程序的请求服务，
  5. 执行完后，操作系统会充值CPU返回用户态，并返回系统调用结果；

* Golang的内存模型

* Epoll原理

* Golang垃圾回收机制GC

  尽量使用数组，有助于垃圾回收效率

  slice本身是一个对象，而map每个元素是一个对象，垃圾回收机制会扫描所有的对象，对象越多，消耗越大

  引用计数：对象被销毁或更新 -1，被创建+1，当为0时销毁；缺点：计数器频繁降低了性能

  标记-清除(mark and sweep)：暂停服务，从根变量迭代标记被引用过的对象，没有标记的对象进行回收，缺点：每次启动垃圾回收，系统暂停，影响程序性能。

  三色标记：停止程序，将所有被变量引用的对象标记灰色，没有引用的标记白色，然后遍历灰色，标记所有被灰色引用的白色，将其标记灰色，对应原来灰色的标记黑色，重复这个动作直到没有灰色；

  golang基于三色标记，重新启动一个协成删除白色；使用插入写屏障和删除写屏障减少stw时间

  分代收集：

* select{} 

  配合for循环可以一直监控channal管道，select默认时阻塞的

* map使用时除非make否则基本不能使用，都是nil

* defer

  多个defer情况下顺序是先进后出，但会对defer中函数的参数求值，但不会进入函数体，并将函数压入调用栈中

* 用户级线程

  多个用户态的线程对应一个内核线程，M：1，程序线程的创建、终止、切换或者同步等线程工作必须由自身完成

* 内核级线程

  多个用户态的线程对应多个内核态线程，1:1，直接调用操作系统的内核线程，所有线程的创建、终止、切换同步工作由内核来完成。C++就是这种

* 双级线程模型

  一个京城中可以对应多个内核级线程，但是进程中的线程不和内核线程一一对应；这种线程模型会先创建多个内核级线程，然后用自身的用户级线程去对应创建的多个内核级线程；

* redis原理 结构 每种使用场景

* 数据结构、算法

* php标准库

* linux

* haspmap数据结构

* http三次握手 7层结构

* mysql索引结构 原理

* 二叉树

  树状的数据结构，结点顺序都是左边小于右边；

  缺点是：如果是自增ID，或变成右边链表结构；

* 红黑树

  基于二叉树，如果二叉树出现了不平衡情况，则会自动旋转调整结点的位置，如果是自增ID的情况下，同样会出现右边偏重的情况，如果数据量非常大，树的高度也很大

  缺点是：自增ID的情况下同样会出现右倾，让树的高度特别大

* B树

  基于多路平衡查找树，每个节点存放多个索引和数据，数据可能是符合条件的完整数据或者是指向数据的地址指针。

  缺点是每个节点存放的索引没有B+树多，并且叶子结点也不是顺序的双向列表；

* B+树

  基于B树，不同的是每个节点中仅保存16大小的索引，叶子结点里面顺序保存了所有的索引和对应的数据（数据可能是符合条件的完整数据，或者是执行符合条件的数据地址的指针）；

* B树和B+树的区别是：

  B树节点中保存的是索引和数据，B+树中保存的是索引，所以节点中B+树可以保存非常多的索引，降低了树的高度

  B+树叶子结点是一个双向链表，便于范围查询，B树则不是

* hash

  mysql的Hash是，对索引进行hash函数得到一个值，这个值在一张hash表中对应的存放着这个索引的数据，

  缺点是没办法进行范围查询，精确查询的效率非常高

  会出现hash碰撞，出现的话会将原索引与查询到的数据逐一对比，影响IO性能

* 聚集索引

  INNODB就是聚集索引，他是在B+树的叶子结点存放了对应的数据，当查到符合条件的索引时就可以直接取出数据；

* 非聚集索引

  MYISAM就是非聚集索引，他在叶子结点存放的是对应的数据的地址指针，当查到符合条件的索引时通过对应的指针定位数据位置；

* 回表

  通过普通索引定位到主键索引，再通过主键索引再聚集索引中查询，当查询的字段仅是普通索引，能直接在叶子结点获取到则不需要回表查询，例如：id是主键，name是普通索引，当查询条件是name="" 查询的字段是id、name就不需要回表。因为直接在普通索引的的叶子结点就能获取到id、name

* 覆盖索引

* INNODB必填有主键，并且最好时自增ID

  首先INNODB是必须要有主键的，因为B+树就是基于组件形成的。如果没有建立主键，INNODB会挑选第一个唯一键作为主键，如果没有唯一键，则会隐形生成一个主键；自增ID的主键能在叶子结点更好向后叠加。如果不是自增则可能产生B+树的结构调整，影响性能；

* 什么情况下没有使用到索引

  使用不等于的情况下

  使用like并且左边是通配符

  当mysql分析后认为全表查询比索引查询更快时

  查询中使用了计算或者函数

  当使用联合索引,前面一个条件为范围查询,后面的即使符合最左前缀原则,也无法使用索引?

* 什么是存储过程？有哪些优缺点？

  将一组特功能的sql集合，提前封装成函数，经过数据库的编译优化存入数据库中，可以通过函数名调用该函数。

  优点：

  ​	存储过程增强了sql语言的灵活性。存储过程可以写流程控制语句，比标准的一条条sql更加灵活；

  ​	存储过程被创建后可以多次使用。

  ​	存储过程执行的速度更快，提前将存储过程分析优化存入数据库中，比标准一条条sql查询逐条分析优化要快很多。

  ​	减少了网络请求流量。将多条sql写成存储过程。只需要传递名称和参数即可；

  ​	将数据的操作集中到存储过程中，数据库管理员可以更好的控制权限；

  创建：

  ````
  -- DELIMITRE // 声明结束符是"//"，否则mysql会将过程中的sql当成标准一条sql执行。
  DELIMITER //
  CREATE PROCEDURE test1(OUT s INT)
  BEGIN
  SELECT count(*) INTO s FROM osp_bill;
  END
  //		-- 结束
  DELIMITER;  -- 再恢复为";"结束
  ````

  调用：

  ````
  set @a=1;
  CALL test1(@i);
  ````

  删除：

  ````
  DROP test1;
  ````

  

* 执行流程

  客户端：发送请求

  连接器：主要身份验证，权限验证。

  查询缓存：先查询缓存，如果命中直接返回，没有命中则进入分析器。缓存中数据是以key-value形式存在，key是查询预计，value是结果集，如果命中则直接返回结果集，没有命中则进入下一步，完成后也会把结果集缓存。数据涉及到的表被修改了，该缓存将失效。8.0取消了缓存功能，因为缓存失效频率非常高。占用内存。

  ````
  select SQL_CACHE * from T where ID=1；-- 使用缓存
  ````

  分析器：分析语法，判断语法是否正确，表字段等基本的规则验证。

  优化器：优化sql，决定使用哪个索引更优，如果联表决定使用各个表的顺序。

  执行器：执行优化之后的sql，调用存储引擎逐条回去数据返回。

  存储引擎：

  ​	MYISAM支持表锁，INNODB支持行锁（有条件的行锁，必须有索引字段）

  ​	MYSIAM不支持事务，INNODB支持事务

  ​	MYISAM支持全文检索，IMMODB不支持全文检索

  ​	查询的时候MYSIAM不会自动排序，INNODB会自动排序

  ​	Memory：数据至于内存的搜索引起，拥有极高的插入、更新、查询效率，但会占用和数据量成正比的内存大小。mysql重启后就会丢失

  ​	Archive：只支持数据的查询和插入

  ​	Merge：

  返回：查询结果逐条返回

* 事务

  原子性、隔离性、完整性

  事务的操作都放在事务日志中，完成提交

* SQL优化

  大数据优化：

  ​	选择合适的存储引擎，

  ​	适当的加索引

  ​	分区分表

  ​	读写分离，主从分离

  ​	可以使用中间件缓存部分数据

  ​	优化查询sql，尽量使用索引，避免回表；

* 脏读：读到了未提交的事务里面的数据

* myisamchk：MYSIAM中压缩表，减少存储空间和内存使用

* mysiam中Static和DyNamic：

* 任何标准表最多可以创建16个索引列；

* mysql字段类型了解 

  货币类型 decimal(9,2)

* 基本表和视图和游标

**第一部分：** **通用模块。** 此部分对 MySQL 整体概念、执行流程、数据库引擎、查询缓存、表空间、回表查询、数据类型间的区别、内存表、临时表、删除表的 n 种方式、枚举、视图、数据恢复等相关知识点对应的面试题进行解答。

**第二部分：** **索引模块。** 索引的好坏直接影响数据库的性能，所以索引的面试题也是面试中必问的问题，此部分为索引对应的面试题合集。

**第三部分：** **事务模块。** 事务决定了程序的稳定性，在 MySQL 中的地位也是首屈一指，也是面试中必问的面试题，此部分为事务对应的面试题合集。

**第四部分：** **锁。** 锁包括：全局锁、表锁、行锁、死锁、乐观锁、悲观锁等，不同的数据库引擎支持的锁支持粒度也是不同的，此部分的面试题，让你彻底搞定锁相关的面试题。

**第五部分：** **日志。** 日志看似不起眼，却是 MySQL 主备同步和容灾恢复以及问题排除的关键，当然也是面试中必问的问题，这部分会对不同的数据库引擎中的重点日志，进行详细的介绍。

**第六部分：** **MySQL** 操作命令和内置函数。** MySQL 的操作命令，对于程序员或者 DBA 来说也是必须具备的一项技能，比如，用户和权限的创建、数据库相关信息的查询等，都离不开对 MySQL 命令行的掌握。对内置函数的掌握程度，代表了你对 MySQL 的掌握程度，善用 MySQL 提供的内置函数，会让你有事半功倍的效果，内置函数也是笔试中必考的面试题。

**第七部分：** **性能优化和分布式。** 性能优化和分布式是面试中决定你高度的关键指标，其中性能优化包括了慢查询的分析和处理，对分布式的掌握体现了你的技术深度。

**第八部分：** **开放性问题。** 很多大公司最后也会问一下没有标准答案的开放性问题，以考察面试者的技术能力边界和对待问题的分析思路，这部分助你更平稳的获得 offer。



redis:

redis是一nosql的数据库，是一个巨大的map，支持1秒10万的高并发；redis的数据存放在内存中，所以读取数据特别快。redis采用单线程，所以就没有线程和上下文切换的消耗。

redis的优点：

​	因为数据存放内存中，读写性能高。

​	支持持久化

​	支持事务

​	数据结构丰富。

​	支持主从复制。

redis的缺点：

​	受物理及其机内存限制，数据量超大的时候占用内存会特别高。

redis支持五种数据类型：String	List	Set OrderSet Hash

​	场景：？？？

​		计数器

String：简单的键值对；

List：从两点压入或者弹出元素，

​	场景：

​		将并发变成穿行

Set：无序集合，添加获取一处单个元素，取交集，并集，差集

Hash：键值对应的无序散列表

OrderSet：添加，删除、获取元素，用来排序；

bitmap：？？？

redis持久化：

​	RBD(默认)：按照一定以时间周期将redis的数据保存到磁盘中，文件名为dump.rdb，周期可以通过配置调整。

​	AOF：记录所有的redis请求命令。保存到aof文件中；如果redis宕机，数据都会恢复；缺点是aof文件会越来越到，同样的数据aof会比rdb生成的dump.rdb文件大。

redis过期策略：

​	定时过期：设置key的时候设置过期时间，当达到过期时间自动删除，这种方式对内存很友好，但会占用大量CPU资源取处理过期数据，影响缓存数据的响应效率

​	惰性过期：只有访问一个key的时候才会判断该key有没有过期，过期则清除，这种方式，对最大化的节省CPU，但如果过期的key一直没有访问会占用内存。产生很多的无效数据。

​	定期过期：每个一段时间会扫描一定数据量的key，判断key是否已经过期，这是一种折中的办法，可以通过设置检查时间的间隔和检查时间时长调整到最平衡的状态；

redis的内存淘汰策略：

​	全局key移除策略：

​	当内存不存时，查询数据会报错

​	当内存不足时，会移除内存中使用最近最少的key

​	当内存不足时，在内存中个随机移除某个key

​	过期key移除策略：

​	当内存不足时，移除设置了过期时间的key中最近最少使用的key

​	当内存不足时，移除设置了过期时间的key中某一个key

​	当内存不足时，移除设置了过期时间的key中最早的key

线程模型：？？？

事务：？？？

集群方案：

​	哨兵：至少需要三个实例

​		集群监控：负责监控redis master和slave进程工作是否正常

​		消息通知：如果某个redis故障，可以发送消息作为警报通知管理员

​		故障转移：如果master node挂掉了，或自动将一个slave node作为master

​		配置中心：如果故障转移发生了，通知client客户端新的master地址

集群的工作原理：？？？

集群下key的寻址策略：？？？

​	hash算法：大量的缓存重建

​	一致性hash算法（自动缓存迁移）+虚拟节点（自动负载均衡）

​	redis cluster的hash的slot算法

一致性hash算法：？？？

redis主从复置的核心原理：

​	当启动一个从节点连接主节点时，第一次连接会发送一条执行表示全量同步，这是主节点会启动一个新的线程，开始生成一份RDB文件，并将后面从客户端传过来的命令存入内存中，然后将RDB传给从节点，从节点先将RDB文件保存，然后读取到内存中生成数据，然后主节点再将内存中的指令发送给从节点，从节点同步这部分数据。如果从节点断开链接，再连接后主节点会发送断开后的命令给从节点恢复缺少的数据

节点中内部通信：

​	集中式：

​	Gossip协议：

redis分片、分区

redis分区的实现方案：

​	客户端决定数据会存在哪个节点，从哪个节点读取数据。

​	代理分区，客户端将命令发给代理分区，代理分区决定使用哪个redis节点，

​	查询路由，客户端随机的将命令发送给任意一个redis实例，然后由redis将请求转发给正确的节点。

redis分区的缺点：

​	不能设计多个key的操作，例如两个集合求交集，可能两个集合分别在不同的分区。

​	同时操作多个key则不能使用redis事务。

​	分区后数据备份资源消耗增加，需要从不同的节点获取到RDB或者AOF文件

redLock：

​	redis官方提供的分布式锁，安全性更高，永远只有一个client能拿到锁，不会出现死锁的情况，容错性较高，只有大部分redis节点存活才可以正常提供服务

缓存雪崩：

​	指同一时间缓存大面积失效，所有的情况落在了数据库上，导致数据库压力增大而崩溃。通过减少并发，采用加锁队列的形式降低压力。

缓存穿透：

​	指同一时间缓存和数据库都没有数据，导致大量请求落到了数据库上，增大数据库压力而崩溃



htttp:

IOS七层：

​	应用层：

​	表示层：

​	会话层：

​	运输层：

​	网络层：

​	数据链路层：

​	物理层：

TCP/IP四层：

​	应用层：

​	运输层：

​	网际层：

​	网络接口层：



服务雪崩：

​	当未大量请求未及时处理掉，造成阻塞，导致服务器压力过大崩溃，导致整条链路堵死，不能提供服务；

熔断机制：

​	当服务处理异常时，达到熔断的标准，就直接返回默认值，并抛出异常。让整条链路 部分崩溃

nginx跨域解决方案：设置代理

````
  proxy_pass http://api.8mvs.com;
  proxy_set_header Host $host;
  proxy_set_header X-Real-IP $remote_addr;
  proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
  client_max_body_size 10M;
````

elasticsearch:提供强大的搜索、统计，支持自定义词库，sum，count、avg、min、max

分词：es会将所有需要分词的字段值，按照设置的分词方式，不重复的词存入倒排索引中，每个词都对应着词条出现的文档位置；

分片：将index拆成几份

备份/副本：备份数据，提供查询

filter：过滤器，不进行评分

bool：复合过滤器

constant_score：设置查询以评分模式来执行

must/must_not/should：所有条件都满足/所有条件都不满足/只要满足一个

match：

​	query：内容

​	operator：or 只要匹配一个 and所有搜索的词条都要匹配

​	minimum_should_match：最少需要匹配几个词条

match_pharse：顺序匹配词条

​	analyzer：设置搜索文案的分词方式

​	slop：设置顺序匹配的情况下相隔多少还属于顺序匹配

multi_match：maoti_match（读音）匹配多个字段

​	query：搜索内容

​	fields：["", ""] 匹配多个字段

prefix：匹配以什么开都的

regexp：正则

buld：批量操作，update时没有则添加



简单的shell语法